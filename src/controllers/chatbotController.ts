import { faqMap } from "../helpers/faqData";
import catchAsync from "../utils/catchAsync";
import { WorkloadAnalyzer } from "../utils/workloadAnalyzer";
import RAGService from "../utils/ragService";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.ALIBABA_MODEL_API_KEY,
  baseURL: "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
});

const systemPrompt = `
B·∫°n l√† nh√¢n vi√™n t∆∞ v·∫•n c·ªßa Ryxel Store ‚Äî m·ªôt c·ª≠a h√†ng chuy√™n b√°n gaming gear (chu·ªôt, b√†n ph√≠m, tai nghe, gh·∫ø gaming, v.v...).
H√£y tr·∫£ l·ªùi kh√°ch h√†ng nh∆∞ m·ªôt nh√¢n vi√™n chƒÉm s√≥c kh√°ch h√†ng t·∫≠n t√¢m, th√¢n thi·ªán, ng·∫Øn g·ªçn v√† r√µ r√†ng.

QUAN TR·ªåNG - ƒê·ªãnh d·∫°ng tr·∫£ l·ªùi:
- Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- S·ª≠ d·ª•ng markdown ƒë·ªÉ ƒë·ªãnh d·∫°ng c√¢u tr·∫£ l·ªùi ƒë·∫πp v√† d·ªÖ ƒë·ªçc
- Khi ƒë·ªÅ c·∫≠p ƒë·∫øn s·∫£n ph·∫©m, t·∫°o link ƒë·∫øn trang s·∫£n ph·∫©m theo ƒë·ªãnh d·∫°ng: [T√™n s·∫£n ph·∫©m](${process.env.CLIENT_HOST}/products/product-slug)
- S·ª≠ d·ª•ng **in ƒë·∫≠m** cho th√¥ng tin quan tr·ªçng nh∆∞ gi√° c·∫£, t√≠nh nƒÉng n·ªïi b·∫≠t
- S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ l√†m cho c√¢u tr·∫£ l·ªùi sinh ƒë·ªông h∆°n

H∆Ø·ªöNG D·∫™N T∆Ø∆†NG T√ÅC:
- Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin c·ªßa Ryxel Store
- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn ho·∫∑c kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, h√£y n√≥i "Hi·ªán t·∫°i em ch∆∞a c√≥ th√¥ng tin ch√≠nh x√°c v·ªÅ v·∫•n ƒë·ªÅ n√†y, anh/ch·ªã c√≥ th·ªÉ li√™n h·ªá hotline ho·∫∑c inbox fanpage ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ th√™m nh√©."
- Kh√¥ng b·ªãa th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m, ph∆∞∆°ng th·ª©c thanh to√°n, ph√≠ v·∫≠n chuy·ªÉn, hay ch√≠nh s√°ch n·∫øu ch∆∞a c√≥ s·∫µn trong c√¢u h·ªèi ho·∫∑c trong d·ªØ li·ªáu c·ª≠a h√†ng
- Lu√¥n x∆∞ng h√¥ anh/ch·ªã cho l·ªãch s·ª±, kh√¥ng d√πng t·ª´ ng·ªØ su·ªìng s√£
- Khi t∆∞ v·∫•n s·∫£n ph·∫©m, h√£y ƒë∆∞a ra so s√°nh c·ª• th·ªÉ v√† g·ª£i √Ω ph√π h·ª£p v·ªõi nhu c·∫ßu kh√°ch h√†ng

V√ç D·ª§ ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:
"üéÆ **S·∫£n ph·∫©m n·ªïi b·∫≠t cho game th·ªß:**

1. **[Logitech G502 Hero](${process.env.CLIENT_HOST}/products/logitech-g502-hero)** - ‚≠ê 4.8/5
   - Gi√°: **890.000 VND**
   - DPI: L√™n ƒë·∫øn 25,600
   - Ph√π h·ª£p: Game FPS, MOBA

2. **[Razer DeathAdder V3](${process.env.CLIENT_HOST}/products/razer-deathadder-v3)** - ‚≠ê 4.7/5
   - Gi√°: **1.200.000 VND**  
   - Sensor cao c·∫•p Focus Pro 30K
   - Ph√π h·ª£p: Game MMO, RPG

üí° **G·ª£i √Ω c·ªßa em:** T√πy v√†o ng√¢n s√°ch v√† lo·∫°i game anh/ch·ªã th∆∞·ªùng ch∆°i m√† em s·∫Ω t∆∞ v·∫•n c·ª• th·ªÉ h∆°n!"

CH√çNH X√ÅC V·ªÄ ƒê∆Ø·ªúNG D·∫™N S·∫¢N PH·∫®M:
- PH·∫¢I s·ª≠ d·ª•ng slug th·ª±c c·ªßa s·∫£n ph·∫©m t·ª´ database, KH√îNG t·ª± t·∫°o slug
- ƒê·ªãnh d·∫°ng: [T√™n s·∫£n ph·∫©m](${process.env.CLIENT_HOST}/products/{slug_th·ª±c_t·ª´_database})`;

// Helper function to create product links
function createProductLink(productName: string, productSlug: string): string {
  return `[${productName}](${process.env.CLIENT_HOST}/products/${productSlug})`;
}

// Helper function to format price in VND
function formatPrice(price: number): string {
  return `**${price.toLocaleString("vi-VN")} VND**`;
}

// Intent classification v√† workload tracking
interface WorkloadMetrics {
  intent: string;
  automationRate: number;
  responseTime: number;
  workloadReduced: boolean;
}

function classifyUserIntent(userMessage: string): {
  intent: string;
  automationRate: number;
} {
  const lowerMsg = userMessage.toLowerCase();

  // FAQ queries (50% of total workload, 95% automation)
  const faqKeywords = [
    "b·∫£o h√†nh",
    "ƒë·ªïi tr·∫£",
    "thanh to√°n",
    "v·∫≠n chuy·ªÉn",
    "giao h√†ng",
    "ch√≠nh s√°ch",
    "ph√≠",
  ];
  if (faqKeywords.some((keyword) => lowerMsg.includes(keyword))) {
    return { intent: "faq", automationRate: 95 };
  }

  // Order status (15% of total workload, 80% automation)
  const orderKeywords = [
    "ƒë∆°n h√†ng",
    "ki·ªÉm tra",
    "tr·∫°ng th√°i",
    "giao ch∆∞a",
    "tracking",
    "m√£ ƒë∆°n",
  ];
  if (orderKeywords.some((keyword) => lowerMsg.includes(keyword))) {
    return { intent: "order_status", automationRate: 80 };
  }

  // Product consultation (20% of total workload, 70% automation)
  const productKeywords = [
    "t∆∞ v·∫•n",
    "n√™n mua",
    "so s√°nh",
    "gaming",
    "chu·ªôt",
    "b√†n ph√≠m",
    "tai nghe",
    "recommend",
  ];
  if (productKeywords.some((keyword) => lowerMsg.includes(keyword))) {
    return { intent: "product_consultation", automationRate: 70 };
  }

  // Technical support (10% of total workload, 60% automation)
  const techKeywords = [
    "c√†i ƒë·∫∑t",
    "setup",
    "l·ªói",
    "kh√¥ng ho·∫°t ƒë·ªông",
    "driver",
    "t∆∞∆°ng th√≠ch",
  ];
  if (techKeywords.some((keyword) => lowerMsg.includes(keyword))) {
    return { intent: "technical_support", automationRate: 60 };
  }

  // General inquiries (5% of total workload, 30% automation)
  return { intent: "general", automationRate: 30 };
}

function getRelevantFAQ(userMessage: string): string | null {
  const lowerMsg = userMessage.toLowerCase();
  for (const faq of faqMap) {
    for (const key of faq.keys) {
      if (lowerMsg.includes(key)) {
        return faq.answer;
      }
    }
  }
  return null;
}

// Log workload metrics
function logWorkloadMetrics(metrics: WorkloadMetrics): void {
  const timestamp = new Date().toISOString();
  console.log(`üìä [${timestamp}] Chatbot Metrics:`, {
    intent: metrics.intent,
    automationRate: `${metrics.automationRate}%`,
    responseTime: `${metrics.responseTime}ms`,
    workloadReduced: metrics.workloadReduced ? "‚úÖ Yes" : "‚ùå No",
  });
}

// Save metrics to database for analysis
async function saveWorkloadMetrics(
  metrics: WorkloadMetrics,
  userMessage: string,
  responseType: "faq" | "ai"
): Promise<void> {
  try {
    await WorkloadAnalyzer.saveMetrics({
      intent: metrics.intent,
      automationRate: metrics.automationRate,
      responseTime: metrics.responseTime,
      responseType,
      workloadReduced: metrics.workloadReduced,
      userMessage,
    });
  } catch (error) {
    console.error("Error saving workload metrics:", error);
  }
}

export const getChatbotResponse = catchAsync(async (req, res) => {
  const overallStart = Date.now();
  const userMessage = req.body.message;
  const conversationHistory = req.body.conversationHistory || [];

  // Classify user intent and get automation rate
  const { intent, automationRate } = classifyUserIntent(userMessage);

  // Try FAQ first for simple queries (performance optimization)
  const faqStart = Date.now();
  const matchedFAQ = getRelevantFAQ(userMessage);
  const faqTime = Date.now() - faqStart;

  if (matchedFAQ && intent === "faq") {
    // FAQ response - fast track for policy/general questions
    const totalTime = Date.now() - overallStart;

    const metrics: WorkloadMetrics = {
      intent,
      automationRate,
      responseTime: totalTime,
      workloadReduced: automationRate > 50,
    };

    logWorkloadMetrics(metrics);
    await saveWorkloadMetrics(metrics, userMessage, "faq");
    return res.status(200).json({
      status: "success",
      data: {
        response: matchedFAQ,
        type: "faq",
        intent,
        automationRate,
        responseTime: totalTime,
        workloadReduced: true,
        productLinks: [],
        sources: ["Ryxel Store Policy"],
      },
    });
  }

  // Use RAG for product-related queries and complex questions
  const ragStart = Date.now();
  const ragService = RAGService.getInstance();

  try {
    const ragResponse = await ragService.generateRAGResponse(
      userMessage,
      conversationHistory
    );
    const ragTime = Date.now() - ragStart;
    const totalTime = Date.now() - overallStart;

    const metrics: WorkloadMetrics = {
      intent,
      automationRate,
      responseTime: totalTime,
      workloadReduced: ragResponse.confidence > 0.6,
    };

    logWorkloadMetrics(metrics);
    await saveWorkloadMetrics(metrics, userMessage, "ai");
    res.status(200).json({
      status: "success",
      data: {
        response: ragResponse.answer,
        type: "rag",
        intent,
        automationRate,
        responseTime: totalTime,
        ragProcessingTime: ragTime,
        workloadReduced: ragResponse.confidence > 0.6,
        sources: ragResponse.sources,
        confidence: ragResponse.confidence,
        productLinks: ragResponse.productLinks || [],
        retrievedProducts: ragResponse.retrievedContext.map((p) => ({
          id: p._id,
          name: p.name,
          price: p.price,
          rating: p.rating,
        })),
      },
    });
  } catch (error) {
    console.error("RAG Error, falling back to basic AI:", error);

    // Fallback to basic AI if RAG fails
    const baseMessages = [
      { role: "system", content: systemPrompt },
      { role: "user", content: userMessage },
    ] as OpenAI.Chat.Completions.ChatCompletionMessageParam[];
    if (matchedFAQ) {
      baseMessages.push({
        role: "assistant",
        content: `üìã **Th√¥ng tin ch√≠nh th·ª©c t·ª´ Ryxel Store:**\n\n${matchedFAQ}`,
      });
    }

    const aiStart = Date.now();
    const completion = await openai.chat.completions.create({
      model: "qwen-turbo",
      messages: baseMessages,
    });
    const aiTime = Date.now() - aiStart;
    const totalTime = Date.now() - overallStart;

    const response = completion.choices[0].message.content;
    const metrics: WorkloadMetrics = {
      intent,
      automationRate,
      responseTime: totalTime,
      workloadReduced: automationRate > 50,
    };

    logWorkloadMetrics(metrics);
    await saveWorkloadMetrics(metrics, userMessage, "ai");
    res.status(200).json({
      status: "success",
      data: {
        response,
        type: "ai_fallback",
        intent,
        automationRate,
        responseTime: totalTime,
        aiProcessingTime: aiTime,
        workloadReduced: automationRate > 50,
        productLinks: [],
        sources: ["AI Assistant"],
      },
    });
  }
});

// Analytics endpoints
export const getChatbotAnalytics = catchAsync(async (req, res) => {
  const { timeframe = "day" } = req.query;

  const workloadStats = await WorkloadAnalyzer.getWorkloadStats(
    timeframe as "day" | "week" | "month"
  );
  const performanceStats = await WorkloadAnalyzer.getPerformanceBenchmarks(
    timeframe as "day" | "week" | "month"
  );

  res.status(200).json({
    status: "success",
    data: {
      workloadStats,
      performanceStats,
      summary: {
        workloadReductionAchieved: workloadStats.avgAutomationRate >= 70,
        performanceTargetsMet: {
          faqUnder1s: performanceStats.faq.under1sPercentage >= 95,
          aiUnder2s: performanceStats.ai.under2sPercentage >= 90,
        },
      },
    },
  });
});

export const getBenchmarkReport = catchAsync(async (req, res) => {
  const { timeframe = "day" } = req.query;

  const stats = await WorkloadAnalyzer.getWorkloadStats(
    timeframe as "day" | "week" | "month"
  );
  const performance = await WorkloadAnalyzer.getPerformanceBenchmarks(
    timeframe as "day" | "week" | "month"
  );

  // Generate detailed report
  const report = {
    period: timeframe,
    generatedAt: new Date().toISOString(),

    // Key metrics
    keyMetrics: {
      totalQueries: stats.totalQueries,
      workloadReductionRate: stats.workloadReductionRate,
      avgAutomationRate: stats.avgAutomationRate,
      avgResponseTime: stats.avgResponseTime,
    },

    // Performance benchmarks
    performance: {
      faq: {
        avgResponseTime: performance.faq.avgResponseTime,
        under1sSuccess: performance.faq.under1sPercentage,
        target: "< 1000ms",
        status:
          performance.faq.under1sPercentage >= 95
            ? "‚úÖ ACHIEVED"
            : "‚ùå NEEDS IMPROVEMENT",
      },
      ai: {
        avgResponseTime: performance.ai.avgResponseTime,
        under2sSuccess: performance.ai.under2sPercentage,
        target: "< 2000ms",
        status:
          performance.ai.under2sPercentage >= 90
            ? "‚úÖ ACHIEVED"
            : "‚ùå NEEDS IMPROVEMENT",
      },
    },

    // Workload analysis
    workloadAnalysis: {
      target: "70% reduction",
      achieved: stats.avgAutomationRate,
      status:
        stats.avgAutomationRate >= 70 ? "‚úÖ TARGET MET" : "‚ùå TARGET NOT MET",
      breakdown: stats.intentStats,
    },

    // Recommendations
    recommendations: generateRecommendations(stats, performance),
  };

  res.status(200).json({
    status: "success",
    data: report,
  });
});

function generateRecommendations(
  workloadStats: any,
  performanceStats: any
): string[] {
  const recommendations: string[] = [];

  if (workloadStats.avgAutomationRate < 70) {
    recommendations.push("Improve FAQ coverage to increase automation rate");
    recommendations.push("Train AI model with more domain-specific data");
  }

  if (performanceStats.faq.under1sPercentage < 95) {
    recommendations.push("Optimize FAQ matching algorithm for faster response");
    recommendations.push("Consider caching frequently asked questions");
  }

  if (performanceStats.ai.under2sPercentage < 90) {
    recommendations.push("Optimize AI model inference time");
    recommendations.push(
      "Consider using faster model variants for simple queries"
    );
  }

  if (recommendations.length === 0) {
    recommendations.push(
      "All targets met! Consider expanding chatbot capabilities"
    );
  }

  return recommendations;
}

// RAG management endpoints
export const initializeRAG = catchAsync(async (req, res) => {
  const ragService = RAGService.getInstance();

  console.log("üöÄ Initializing RAG system...");
  const start = Date.now();

  await ragService.indexProducts();

  const duration = Date.now() - start;

  res.status(200).json({
    status: "success",
    message: "RAG system initialized successfully",
    data: {
      indexingTime: duration,
      timestamp: new Date().toISOString(),
    },
  });
});

export const searchProducts = catchAsync(async (req, res) => {
  const { query, limit = 5 } = req.query;

  if (!query) {
    return res.status(400).json({
      status: "error",
      message: "Query parameter is required",
    });
  }

  const ragService = RAGService.getInstance();
  const products = await ragService.retrieveRelevantProducts(
    query as string,
    Number(limit)
  );

  res.status(200).json({
    status: "success",
    data: {
      query,
      products,
      count: products.length,
    },
  });
});

export const getProductRecommendations = catchAsync(async (req, res) => {
  const {
    category,
    brand,
    priceMin,
    priceMax,
    minRating,
    limit = 5,
  } = req.query;

  const ragService = RAGService.getInstance();

  if (category) {
    // Get popular products in category
    const products = await ragService.getPopularProductsInCategory(
      category as string,
      Number(limit)
    );
    return res.status(200).json({
      status: "success",
      data: {
        products,
        criteria: { category },
        count: products.length,
      },
    });
  }

  // Search by criteria
  const criteria: any = {};
  if (brand) criteria.brand = brand;
  if (priceMin || priceMax) {
    criteria.priceRange = {
      min: priceMin ? Number(priceMin) : 0,
      max: priceMax ? Number(priceMax) : 999999999,
    };
  }
  if (minRating) criteria.minRating = Number(minRating);

  const products = await ragService.searchProductsByCriteria(
    criteria,
    Number(limit)
  );

  res.status(200).json({
    status: "success",
    data: {
      products,
      criteria,
      count: products.length,
    },
  });
});
